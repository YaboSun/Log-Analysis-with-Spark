package kafka;import kafka.consumer.Consumer;import kafka.consumer.ConsumerConfig;import kafka.consumer.ConsumerIterator;import kafka.consumer.KafkaStream;import kafka.javaapi.consumer.ConsumerConnector;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.Properties;/** * @author YaboSun */public class KafkaConsumer extends Thread {    private String topic;    public KafkaConsumer(String topic) {        this.topic = topic;    }    private ConsumerConnector createConnector() {        Properties properties = new Properties();        properties.put("zookeeper.connect", KafkaProperties.ZK);        properties.put("group.id", KafkaProperties.GROUP_ID);        ConsumerConfig consumerConfig = new ConsumerConfig(properties);        return Consumer.createJavaConsumerConnector(consumerConfig);    }    @Override    public void run() {        ConsumerConnector consumer = createConnector();        Map<String, Integer> messageMap = new HashMap<String, Integer>();        messageMap.put(topic, 1);        // String:表示topic        // List<KafkaStream<byte[], byte[]>>:表示对应的数据流？？        Map<String, List<KafkaStream<byte[], byte[]>>> messageStreams =                consumer.createMessageStreams(messageMap);        // 获取每次接收到的数据.因为可能有多个topic，所以可以通过map的索引来指定输出的topic        KafkaStream<byte[], byte[]> kafkaStream = messageStreams.get(topic).get(0);        ConsumerIterator<byte[], byte[]> consumerIterator = kafkaStream.iterator();        while (consumerIterator.hasNext()) {            String message = new String(consumerIterator.next().message());            System.out.println("receive: " + message);        }    }}